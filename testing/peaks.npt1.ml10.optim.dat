# Problem setup: datafolder           data 
#                training examples    Ytrain_orig.dat 
#                training labels      Ctrain_orig.dat 
#                validation examples  Yval_orig.dat 
#                validation labels    Cval_orig.dat 
#                ntraining            5000 
#                nvalidation          200 
#                nfeatures            2 
#                nclasses             5 
#                nchannels            8 
#                nlayers              30 
#                T                    5.000000 
#                network type         dense 
#                Activation           SmoothReLU 
#                openlayer type       1 
# XBraid setup:  max levels           10 
#                min coarse           10 
#                coasening            2 
#                coasening (level 0)  2 
#                max. braid iter      2 
#                abs. tol             1e-15 
#                abs. toladj          1e-15 
#                print level          1 
#                access level         0 
#                skip?                0 
#                fmg?                 0 
#                nrelax (level 0)     0 
#                nrelax               1 
# Optimization:  optimization type    deterministic 
#                nbatch               5000 
#                gamma_tik            1e-07 
#                gamma_ddt            1e-07 
#                gamma_class          1e-07 
#                stepsize type        backtracking line-search 
#                stepsize             1.000000 
#                max. optim iter      20 
#                gtol                 1e-04 
#                max. ls iter         20 
#                ls factor            0.500000 
#                weights_init         0.001000 
#                weights_open_init    0.000000 
#                weights_class_init   0.001000 
#                hessianapprox_type   L-BFGS 
#                lbfgs_stages         20 
#                validationlevel      1 

#    || r ||          || r_adj ||      Objective             Loss                  || grad ||          Stepsize  LSiter  Epoch   Accur_train  Accur_val   Time(sec)
000  1.05426534e-05  7.01718976e-13  1.60941989766493e+00  1.60941989718846e+00  5.47547519325757e-01  1.000000   0         0        20.18%      21.00%     1.5
001  1.58004948e-17  2.03041298e-10  1.38071340216910e+00  1.38071338670040e+00  3.06050567716981e-01  1.000000   0         1        48.00%      46.50%     3.7
002  7.29308617e-13  4.22213509e-10  1.23596253137683e+00  1.23596243974066e+00  1.29391394257780e-01  1.000000   0         2        50.78%      48.50%     6.3
003  9.81124666e-13  2.07669782e-10  1.20341417342464e+00  1.20341402994788e+00  1.18831935496276e-01  1.000000   0         3        56.24%      54.50%     9.5
004  6.26066795e-12  4.49854737e-10  1.18418442453580e+00  1.18418421274440e+00  7.58416506674423e-02  1.000000   0         4        56.98%      54.00%     11.9
005  6.78105909e-12  2.17426183e-10  1.17681138506101e+00  1.17681114353765e+00  4.93204360796169e-02  1.000000   0         5        58.80%      56.00%     15.0
006  2.30351730e-11  3.40981732e-10  1.16939416065256e+00  1.16939389207214e+00  5.63229160588511e-02  1.000000   0         6        58.22%      54.00%     18.1
007  8.88623265e-11  7.08703623e-10  1.15848320762452e+00  1.15848290381382e+00  8.77505478477235e-02  1.000000   0         7        54.00%      50.00%     21.4
008  1.53502187e-09  3.43627498e-09  1.15752458099279e+00  1.15752415760564e+00  2.70258261861007e-01  1.000000   0         8        56.42%      53.50%     24.5
009  3.35426626e-10  2.10759273e-09  1.14272215805333e+00  1.14272179436899e+00  1.28969655129396e-01  1.000000   0         9        52.74%      46.00%     27.4
010  8.65490677e-11  1.05329993e-09  1.14123385478707e+00  1.14123346978231e+00  1.55750623407506e-01  1.000000   0        10        53.14%      48.00%     30.0
011  2.41000293e-10  5.31010337e-10  1.13494612729255e+00  1.13494572513913e+00  6.54530806420007e-02  1.000000   0        11        55.90%      51.00%     32.2
012  1.84660098e-09  1.94338217e-09  1.13142768073210e+00  1.13142720629247e+00  1.25443138882349e-01  1.000000   0        12        51.96%      49.00%     34.4
013  8.54540923e-10  1.12055818e-09  1.12358278356824e+00  1.12358229180074e+00  1.11310852815528e-01  1.000000   0        13        55.88%      54.50%     36.4
014  1.64024146e-08  7.14719084e-09  1.11134576834467e+00  1.11134514381860e+00  1.40185628559133e-01  1.000000   0        14        57.94%      56.50%     38.5
015  9.73572966e-09  2.81897201e-09  1.10494151034690e+00  1.10494084600873e+00  1.15680085929716e-01  1.000000   0        15        60.98%      57.00%     40.9
016  3.27161110e-08  5.09705006e-09  1.09542616968120e+00  1.09542542799468e+00  2.51017228904251e-01  1.000000   0        16        60.68%      57.50%     42.9
017  3.55387932e-07  1.33789499e-08  1.08242275846185e+00  1.08242181907882e+00  5.74669282314449e-01  1.000000   0        17        59.18%      57.50%     45.0
018  1.35900404e-08  1.27840638e-08  1.07817898750935e+00  1.07817806809746e+00  3.68508030725754e-01  1.000000   0        18        58.34%      56.00%     47.1
019  9.54593730e-08  1.10671022e-08  1.07641618944743e+00  1.07641542511825e+00  5.40433679345313e-01  1.000000   0        19        58.12%      53.50%     49.5
