# Problem setup: datafolder           data 
#                training examples    Ytrain_orig.dat 
#                training labels      Ctrain_orig.dat 
#                validation examples  Yval_orig.dat 
#                validation labels    Cval_orig.dat 
#                ntraining            5000 
#                nvalidation          200 
#                nfeatures            2 
#                nclasses             5 
#                nchannels            8 
#                nlayers              30 
#                T                    5.000000 
#                network type         dense 
#                Activation           SmoothReLU 
#                openlayer type       1 
# XBraid setup:  max levels           10 
#                min coarse           10 
#                coasening            2 
#                coasening (level 0)  2 
#                max. braid iter      2 
#                abs. tol             1e-15 
#                abs. toladj          1e-15 
#                print level          1 
#                access level         0 
#                skip?                0 
#                fmg?                 0 
#                nrelax (level 0)     0 
#                nrelax               1 
# Optimization:  optimization type    deterministic 
#                nbatch               5000 
#                gamma_tik            1e-07 
#                gamma_ddt            1e-07 
#                gamma_class          1e-07 
#                stepsize type        backtracking line-search 
#                stepsize             1.000000 
#                max. optim iter      20 
#                gtol                 1e-04 
#                max. ls iter         20 
#                ls factor            0.500000 
#                weights_init         0.001000 
#                weights_open_init    0.000000 
#                weights_class_init   0.001000 
#                hessianapprox_type   L-BFGS 
#                lbfgs_stages         20 
#                validationlevel      1 

#    || r ||          || r_adj ||      Objective             Loss                  || grad ||          Stepsize  LSiter  Epoch   Accur_train  Accur_val   Time(sec)
000  1.05426534e-05  7.01718976e-13  1.60941989766493e+00  1.60941989718846e+00  5.47547519325757e-01  1.000000   0         0        20.18%      21.00%     1.1
001  1.58004948e-17  2.03041298e-10  1.38071340216910e+00  1.38071338670040e+00  3.06050567716981e-01  1.000000   0         1        48.00%      46.50%     3.0
002  7.29308618e-13  4.22213509e-10  1.23596253137683e+00  1.23596243974066e+00  1.29391394257780e-01  1.000000   0         2        50.78%      48.50%     4.7
003  9.81124683e-13  2.07669782e-10  1.20341417342464e+00  1.20341402994788e+00  1.18831935496276e-01  1.000000   0         3        56.24%      54.50%     6.1
004  6.26066783e-12  4.49854737e-10  1.18418442453580e+00  1.18418421274440e+00  7.58416506674425e-02  1.000000   0         4        56.98%      54.00%     7.8
005  6.78105908e-12  2.17426183e-10  1.17681138506101e+00  1.17681114353765e+00  4.93204360796169e-02  1.000000   0         5        58.80%      56.00%     9.3
006  2.30351730e-11  3.40981732e-10  1.16939416065256e+00  1.16939389207214e+00  5.63229160588514e-02  1.000000   0         6        58.22%      54.00%     10.8
007  8.88623267e-11  7.08703623e-10  1.15848320762452e+00  1.15848290381382e+00  8.77505478477244e-02  1.000000   0         7        54.00%      50.00%     12.2
008  1.53502187e-09  3.43627498e-09  1.15752458099279e+00  1.15752415760564e+00  2.70258261860990e-01  1.000000   0         8        56.42%      53.50%     13.6
009  3.35426627e-10  2.10759273e-09  1.14272215805333e+00  1.14272179436899e+00  1.28969655129394e-01  1.000000   0         9        52.74%      46.00%     15.0
010  8.65490675e-11  1.05329993e-09  1.14123385478707e+00  1.14123346978231e+00  1.55750623407503e-01  1.000000   0        10        53.14%      48.00%     16.5
011  2.41000293e-10  5.31010337e-10  1.13494612729255e+00  1.13494572513913e+00  6.54530806420003e-02  1.000000   0        11        55.90%      51.00%     18.0
012  1.84660098e-09  1.94338217e-09  1.13142768073210e+00  1.13142720629247e+00  1.25443138882352e-01  1.000000   0        12        51.96%      49.00%     19.4
013  8.54540923e-10  1.12055818e-09  1.12358278356824e+00  1.12358229180074e+00  1.11310852815525e-01  1.000000   0        13        55.88%      54.50%     20.8
014  1.64024146e-08  7.14719084e-09  1.11134576834467e+00  1.11134514381860e+00  1.40185628559138e-01  1.000000   0        14        57.94%      56.50%     22.2
015  9.73572966e-09  2.81897201e-09  1.10494151034690e+00  1.10494084600873e+00  1.15680085929726e-01  1.000000   0        15        60.98%      57.00%     23.6
016  3.27161110e-08  5.09705006e-09  1.09542616968120e+00  1.09542542799468e+00  2.51017228904272e-01  1.000000   0        16        60.68%      57.50%     25.0
017  3.55387932e-07  1.33789499e-08  1.08242275846185e+00  1.08242181907881e+00  5.74669282314278e-01  1.000000   0        17        59.18%      57.50%     26.5
018  1.35900404e-08  1.27840638e-08  1.07817898750934e+00  1.07817806809745e+00  3.68508030724424e-01  1.000000   0        18        58.34%      56.00%     27.8
019  9.54593730e-08  1.10671022e-08  1.07641618944740e+00  1.07641542511821e+00  5.40433679346081e-01  1.000000   0        19        58.12%      53.50%     29.3
