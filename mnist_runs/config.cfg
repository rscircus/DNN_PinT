################################
# Data set 
################################

# relative data folder location 
#datafolder = /Users/jacobschroder/joint_repos/DNN_PinT/data
#datafolder = /space/eccyr/Projects/ECRP/Code/convnet/mnist_converter
datafolder = /Users/eccyr/Projects/ECRP/Code/xbraid-connets/mnist_converter
# training examples filename
ftrain_ex = MNIST_Ytrain.dat
# training labels/classes filename 
ftrain_labels = MNIST_Ctrain.dat
# validation examples filename
fval_ex = MNIST_Yval.dat
# validation labels/classes filename
fval_labels = MNIST_Cval.dat
# number of training data elements
ntraining = 5000
# number of validation data elements
nvalidation = 200
# number of features in training and validation examples 
nfeatures = 784
# number of labels/classes
nclasses = 10

################################
# Neural Network  
################################

# number of channels for (convolutional networks this is nfeatures times the number of convolutions)
#    6272 => 8 output channels, 4784 => 6, 3920 => 5, 3136 => 4
nchannels = 3136
# number of layers (minimum two, opening layer and classification layer)
nlayers = 20
# final time
T = 5.0
# Activation function ("tanh" or "ReLu" or "SmoothReLu")
activation = tanh 
# Type of network ("dense" the default, or "convolutional")
network_type = convolutional
# Opening layer type.  
#  "replicate": replicate image for each convolution.  
#  "activate": same as replicate, only apply tuned, shifted tanh activation function for MNIST. 
type_openlayer = activate 
# factor for scaling initial opening layer weights and bias
weights_open_init = 1e-3
# factor for scaling initial weights and bias of intermediate layers
weights_init = 1e-3
# factor for scaling initial classification weights and bias 
weights_class_init = 1e-3

################################
#BRAID 
################################

# coarsening factor
braid_cfactor = 2 
# maximum number of levels 
braid_maxlevels = 1
# maximum number of iterations
braid_maxiter = 10
# absolute tolerance
braid_abstol = 1e-10
# absolute adjoint tolerance
braid_adjtol = 1e-10
# printlevel
braid_printlevel = 1
# access level
braid_accesslevel = 0 
# skip work on downcycle?
braid_setskip = 0 
# V-cycle (0) or full multigrid  (1)
braid_fmg = 0
# Number of CF relaxations
braid_nrelax = 2 

####################################
#Optimization
####################################

# relaxation param for tikhonov term
gamma_tik = 1e-7
# relaxation param for time-derivative term
gamma_ddt = 1e-7
# relaxation param for tikhonov term of classification weights 
gamma_class = 1e-7
# initial stepsize
stepsize = 1.0
# maximum number of optimization iterations
optim_maxiter = 24
# absolute stopping criterion for the gradient norm
gtol = 1e-4
# maximum number of linesearch iterations
ls_maxiter = 20
# factor for modifying the stepsize within a linesearch iteration
ls_factor = 0.5
# Hessian Approximation ("BFGS", "L-BFGS" or "Identity")
hessian_approx = L-BFGS 
# number of stages for l-bfgs method 
lbfgs_stages = 20

